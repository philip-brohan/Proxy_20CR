
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Machine Learning for Data Assimilation &#8212; Machine Learning for Data Assimilation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxdoc.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">ML for DA</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Machine Learning for Data Assimilation</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="machine-learning-for-data-assimilation">
<h1>Machine Learning for Data Assimilation<a class="headerlink" href="#machine-learning-for-data-assimilation" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://reanalyses.org">Reanalysis</a> is awesome, but it’s very slow and very expensive. We can make it dramatically easier and cheaper with <a class="reference external" href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning</a>.</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/Intro_figure.jpg"><img alt="_images/Intro_figure.jpg" src="_images/Intro_figure.jpg" style="width: 95%;" /></a>
</figure>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>We would like to know the weather everywhere in the world, for every hour in the last 100 years at least. But for most times, and most places, we have no observations of the weather. So we need to use the observations we do have as efficiently as possible - we need to make each observation inform our estimates of the weather in places remote from the observation. A powerful technique for this is <a class="reference external" href="https://en.wikipedia.org/wiki/Data_assimilation">Data Assimilation (DA)</a> which starts from a model of the weather, and uses observations to constrain the state of the model. Using DA with <a class="reference external" href="https://en.wikipedia.org/wiki/General_circulation_model">General circulation Models (GCMs)</a> has been enormously successful, providing precise and accurate estimates of global weather, operational weather forecasts, comprehensive modern reanalyses such as <a class="reference external" href="https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5">ERA5</a> and long sparse-observation reanalyses such as the <a class="reference external" href="https://psl.noaa.gov/data/20thC_Rean/">Twentieth Century Reanalysis (20CR)</a>.
But GCMs are complex to use and expensive to run. Reanalysis projects require specialist expertise and enormous quantities of supercomputer time, so this technology, despite its power, is not very widely used. We already know that that we can use Machine Learning (ML) to make <a class="reference external" href="https://brohan.org/ML_GCM/">fast approximations to a GCM</a>, can we extend this to do DA as well?</p>
<p>Here I show that you can use a <a class="reference external" href="https://en.wikipedia.org/wiki/Variational_autoencoder">Variational AutoEncoder (VAE)</a> to build a fast <a class="reference external" href="https://en.wikipedia.org/wiki/Generative_model#Deep_generative_models">deep generative model</a> linking physically-plausible weather fields to a complete, continuous, low-dimensional latent space. Data Assimilation can then be done by searching the latent space for the state that maximises the fit between the linked field and the observations. The DA process takes about 1 minute on a standard laptop.</p>
</section>
<section id="generative-model-and-latent-space">
<h2>Generative model, and latent space<a class="headerlink" href="#generative-model-and-latent-space" title="Permalink to this headline">¶</a></h2>
<p>The objective is to transform a set of observations to the underlying weather field. More reasonably, we want an estimate of the underlying field and a measure of the uncertainty of that estimate. So there is some function <code class="docutils literal notranslate"><span class="pre">f()</span></code> where:</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/f_obs_map_to_field.jpg"><img alt="_images/f_obs_map_to_field.jpg" src="_images/f_obs_map_to_field.jpg" style="width: 95%;" /></a>
</figure>
<p>(Here, as in all these examples, the field is the 2m air temperature (T2m) anomaly, from ERA5, at a 0.25 degree resolution). We can also express this as:</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/f_obs_txt_to_field.jpg"><img alt="_images/f_obs_txt_to_field.jpg" src="_images/f_obs_txt_to_field.jpg" style="width: 95%;" /></a>
</figure>
<p>Where each <code class="docutils literal notranslate"><span class="pre">O</span></code> is a triplet of (lat, lon, T2m anomaly) and <code class="docutils literal notranslate"><span class="pre">n</span></code> is a variable - we need to be able to use any number of observations. The challenge is to use ML to make a suitable <code class="docutils literal notranslate"><span class="pre">f()</span></code>.</p>
<p>We are going to replace the GCM with a generative model. Recent work in ML has generated some terrifyingly good generative models. The person below, for example, <a class="reference external" href="https://this-person-does-not-exist.com/en">does not exist</a>.</p>
<figure class="align-center" style="width: 60%">
<a class="reference internal image-reference" href="_images/Person_that_does_not_exist.jpg"><img alt="_images/Person_that_does_not_exist.jpg" src="_images/Person_that_does_not_exist.jpg" style="width: 60%;" /></a>
</figure>
<p>This picture is not a photograph, it is the output from an ML model (<a class="reference external" href="https://github.com/NVlabs/stylegan2">StyleGAN2</a>, via <a class="reference external" href="https://this-person-does-not-exist.com/en">this-person-does-not-exist.com</a>). The model here is serving as a function that takes 512 numbers as an input (usually generated at random) and converts them into a photo-realistic picture. We call this function a generator - <code class="docutils literal notranslate"><span class="pre">g()</span></code>.</p>
<figure class="align-center" style="width: 80%">
<a class="reference internal image-reference" href="_images/g_to_tpdne.jpg"><img alt="_images/g_to_tpdne.jpg" src="_images/g_to_tpdne.jpg" style="width: 80%;" /></a>
</figure>
<p>The inputs <code class="docutils literal notranslate"><span class="pre">X</span></code> form a vector in 512-dimensional space. We call this input space the <em>latent space</em> and the model is trained to map any point in this space into a photo-realistic picture. (Strictly, any point close to the origin - the <code class="docutils literal notranslate"><span class="pre">X</span></code> should be a sample from a multivariate normal distribution with mean 0 and variance 1).</p>
<p>If we can do this for photos of faces, then we can do it for weather fields (ERA5 T2m anomaly). The temperature field is much simpler than the face picture, so I’m reducing the latent space dimension to 100 (arbitrary, makes training easier and faster), but otherwise we can build the same generator function for that.</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/g_ls_to_t2m.jpg"><img alt="_images/g_ls_to_t2m.jpg" src="_images/g_ls_to_t2m.jpg" style="width: 95%;" /></a>
</figure>
<p>I’m going to create this generator - <code class="docutils literal notranslate"><span class="pre">g()</span></code> - using a <a class="reference external" href="https://en.wikipedia.org/wiki/Variational_autoencoder">Variational AutoEncoder (VAE)</a>. An autoencoder is a pair of neural nets: one of them (the encoder) compresses an input field into the low-dimensional latent space, and the other (the generator) expands the small latent space representation back into the input field. They are trained as a pair - optimising to make generator(encoder(input)) as close to the original input as possible. A variational autoencoder is an autoencoder where the latent space is constrained to be continuous (two close points in the latent space should produce two similar states when decoded), and complete (any point sampled from the latent space should give a plausible T2m anomaly field if used as input to the generator). This means the generator network can be used independently of the encoder to make new states similar to the original inputs.</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/DCVAE.jpg"><img alt="_images/DCVAE.jpg" src="_images/DCVAE.jpg" style="width: 95%;" /></a>
</figure>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="model.html">Details: Building and training the VAE</a></li>
</ul>
</div>
<p>Training a simple VAE on 40 years of daily T2m anomalies (from ERA5) gives decent results after only about 10 minutes (on a single v100 GPU).</p>
<figure class="align-center" id="id2" style="width: 95%">
<a class="reference internal image-reference" href="_images/DCVAE_validation.jpg"><img alt="_images/DCVAE_validation.jpg" src="_images/DCVAE_validation.jpg" style="width: 95%;" /></a>
<figcaption>
<p><span class="caption-text">VAE validation: top left - original field, top right - generator output, bottom left - difference, bottom right - scatter original::output. (Note that a substantially better result could be produced with more model-building effort and a larger latent space, but this is good enough for present purposes).</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>The successful  model training means that the generator half of the VAE can serve as our <code class="docutils literal notranslate"><span class="pre">g()</span></code> taking any point in a 100-dimensional latent space (close to the origin, as above) and mapping it to a never-before-seen, but physically-plausible, daily T2m anomaly field. Importantly, this <code class="docutils literal notranslate"><span class="pre">g()</span></code> is both accurate and <em>fast</em>  - sample weather fields can be produced in a small fraction of a second.</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/DCVAE_to_g_latent.jpg"><img alt="_images/DCVAE_to_g_latent.jpg" src="_images/DCVAE_to_g_latent.jpg" style="width: 95%;" /></a>
</figure>
</section>
<section id="assimilating-through-the-latent-space">
<h2>Assimilating through the latent space<a class="headerlink" href="#assimilating-through-the-latent-space" title="Permalink to this headline">¶</a></h2>
<p>But we don’t want <code class="docutils literal notranslate"><span class="pre">g()</span></code> - the function making a weather field from a latent space vector; we want <code class="docutils literal notranslate"><span class="pre">f()</span></code> - a function making a weather field from a variable set of observations. The virtue of having <code class="docutils literal notranslate"><span class="pre">g()</span></code>, is that it allows us to convert the problem from finding a weather field that matches the observations, to finding a point in latent space that generates a weather field that matches the observations - we map observations to latent space vector to field. That is, we can look for the solution in the latent space, rather than in the real-space weather field.</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/f_obs_to_latent_to_field.jpg"><img alt="_images/f_obs_to_latent_to_field.jpg" src="_images/f_obs_to_latent_to_field.jpg" style="width: 95%;" /></a>
</figure>
<p>This is a gain because the latent space, unlike real space, is <em>complete</em> and <em>continuous</em>. We can’t just perturb the real-space weather field to make a field that matches observations - there are a large number of real-space fields that match the observations, but almost all of them are physically-impossible, they don’t represent plausible weather states. The latent space does not have this problem, every point in latent space represents a plausible weather state. So if we can find a point in latent space which, when used as input to <code class="docutils literal notranslate"><span class="pre">g()</span></code>, produces a real-space field that matches the observations, that real space field is a satisfactory solution to the assimilation problem. And because the latent space is also continuous, we can search for the best point in latent space with an <a class="reference external" href="https://en.wikipedia.org/wiki/Mathematical_optimization">optimiser</a>, which means we can find the best-fit latent space vector (and so weather state) efficiently. For this example case (100-dimensional latent space representation of ERA5 T2m, fit to a few thousand observations), it takes in only about 100 iterations (i.e. about 100 calls of the generator) - and because <code class="docutils literal notranslate"><span class="pre">g()</span></code> is very fast, the whole process takes little time, less than one minute on a standard laptop (no GPU).</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/Optimiser.jpg"><img alt="_images/Optimiser.jpg" src="_images/Optimiser.jpg" style="width: 95%;" /></a>
</figure>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="optimiser.html">Details: DA by optimisation in latent space</a></li>
</ul>
</div>
<p>This optimisation search provides our function <code class="docutils literal notranslate"><span class="pre">f()</span></code> and it is simple to extend it to provide uncertainty estimates as well. Call the function several times with different starting guesses for the latent space vector <code class="docutils literal notranslate"><span class="pre">X</span></code> (and, if desired, perturbations to the observations to account for their uncertainty), and the resulting ensemble of real space fields provides a sample constrained by the observations.</p>
<figure class="align-center" style="width: 95%">
<a class="reference internal image-reference" href="_images/DCVAE_to_optimiser_to_DA.jpg"><img alt="_images/DCVAE_to_optimiser_to_DA.jpg" src="_images/DCVAE_to_optimiser_to_DA.jpg" style="width: 95%;" /></a>
</figure>
<p>To check that it works, we can make some pseudo-observations from a known field, and see how well we can recover the original field from just the observations:</p>
<figure class="align-center" id="id3" style="width: 95%">
<a class="reference internal image-reference" href="_images/fit_1969.jpg"><img alt="_images/fit_1969.jpg" src="_images/fit_1969.jpg" style="width: 95%;" /></a>
<figcaption>
<p><span class="caption-text">Assimilation validation: bottom - original field (ERA5 T2m anomaly), top - assimilation results. Black dots mark observations assimilated, grey hatching marks regions where the result is very uncertain.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>This process works as expected. We can reconstruct the weather field precisely in regions where we have observations, and with uncertainty in regions where observations are unavailable.</p>
<p>It’s not just T2m - the same approach can be used over a wide range of applications.</p>
</section>
<section id="examples-of-use">
<h2>Examples of use<a class="headerlink" href="#examples-of-use" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="haduk-grid.html">You don't have to start from GCM output - working with haduk-grid</a></li>
<li class="toctree-l1"><a class="reference internal" href="conversion.html">Assimilating things other than observations - dataset to dataset conversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="mslp.html">Not just T2m - assimilating mslp</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi-variable.html">Not just one variable - finding mslp by assimilating wind observations</a></li>
</ul>
</div>
</section>
<section id="conclusions">
<h2>Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">¶</a></h2>
<p>Machine Learning makes data assimilation easy, cheap, and fast. The recipe is:</p>
<ol class="arabic simple">
<li><p>Train a variational autoencoder on a sample of the desired output</p></li>
<li><p>Find a point in latent space which, when run through the resulting generator function, matches the observations.</p></li>
</ol>
<p>This is made possible by the new capabilities offered by ML, and particularly the <a class="reference external" href="https://en.wikipedia.org/wiki/Variational_autoencoder">VAE</a> which provides a straightforward method for creating a latent space, and a generator function <code class="docutils literal notranslate"><span class="pre">g()</span></code>, which is both expressive and fast. It would be extraordinarily difficult to code such a function by traditional methods.</p>
</section>
<section id="small-print">
<h2>Small print<a class="headerlink" href="#small-print" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="how_to.html">How to reproduce or extend this work</a></li>
<li class="toctree-l1"><a class="reference internal" href="credits.html">Authors and acknowledgements</a></li>
</ul>
</div>
<p>This document is crown copyright (2022). It is published under the terms of the <a class="reference external" href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/2/">Open Government Licence</a>. Source code included is published under the terms of the <a class="reference external" href="https://opensource.org/licenses/BSD-2-Clause">BSD licence</a>.</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/reconstructed.png" alt="Logo"/>
            </a></p>
<h3><a href="index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model.html">Details: Building and training the VAE</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="optimiser.html">Details: DA by optimisation in latent space</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="haduk-grid.html">You don't have to start from GCM output - working with haduk-grid</a></li>
<li class="toctree-l1"><a class="reference internal" href="conversion.html">Assimilating things other than observations - dataset to dataset conversion</a></li>
<li class="toctree-l1"><a class="reference internal" href="mslp.html">Not just T2m - assimilating mslp</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi-variable.html">Not just one variable - finding mslp by assimilating wind observations</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="how_to.html">How to reproduce or extend this work</a></li>
<li class="toctree-l1"><a class="reference internal" href="credits.html">Authors and acknowledgements</a></li>
</ul>
<h3><a href="https://github.com/philip-brohan/Proxy_20CR">Get a copy</a></h3>

<ul>
<li><a href="https://github.com/philip-brohan/Proxy_20CR"
           rel="nofollow">Github repository</a></li>
</ul>

<h3>Found a bug, or have a suggestion?</h3>

Please <a href="https://github.com/philip-brohan/Proxy_20CR/issues/new">raise an issue</a>.
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">ML for DA</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Machine Learning for Data Assimilation</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    </div>
  </body>
</html>